{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platt Burges\n",
    "\n",
    "&nbsp;\n",
    "    \n",
    "This script solves Platt-Burges model via regularized least squares with L2 norm penalty (Ridge Regression). Albeit the default solver in our repository is Expectation Maximization algorithm. Certainly there are merits to EM algorithm. \n",
    "\n",
    "1. You have a more detailed derivation from Stanford CS229 Autumn 2016 Problem Set 4 Problem 2. \n",
    "2. EM algorithm can give us the standard deviation of both intrinsic value and bias level whereas RLS only yields the mean of intrinsic value and bias level.\n",
    "\n",
    "Despite all the malaises we list out, why are we doing RLS?\n",
    "\n",
    "1. RLS is fast and straight forward. No need to get stuck in prior and posterior distribution.\n",
    "2. RLS can work on incomplete matrix via L2 norm regularization. The penalty is on reviewer bias when some reviewers have not reviewed all the papers. Although the coefficient of penalty could be arbitrary as we cannot use cross validation to obtain the optima. Moreover, the adjacency matrix does not have to be binary to indicate a reviewer has reviewed a paper. The adjacency matrix can be modified into a confidence matrix where each element is within [0,1].\n",
    "\n",
    "Assuming $P$ papers are submitted to the conference and $R$ reviewers in the committee mark the score of these papers, each paper will be given $R$ different scores by all the reviewers. Therefore, the score of a paper given by a reviewer, denoted as $x$, can be decomposed into the linear combination of three components â€“ the underlying intrinsic value $y$, the reviewer bias $z$ and some random disturbance $\\epsilon$. $x$, $y$ and $z$ independently follow different Gaussian distributions.\n",
    "\n",
    "$$ y^{(pr)} \\sim \\mathcal{N} (\\mu_p,\\sigma_p^2)$$\n",
    "\n",
    "$$ z^{(pr)} \\sim \\mathcal{N} (\\nu_r,\\tau_r^2)$$\n",
    "\n",
    "$$ x^{(pr)}|y^{(pr)},z^{(pr)} \\sim \\mathcal{N} (y^{(pr)}+z^{(pr)},\\sigma^2)$$\n",
    "\n",
    "RLS solves Platt-Burges model by minimizing the loss function $\\mathcal{L}$. $\\lambda$ denotes the coefficient of L2 penalty. $A^{(pr)}$ denotes the adjacency matrix (or confidence matrix) where not every reviewer reviews all the papers. When the adjacency matrix is filled with ones, $\\lambda$ should be zero. \n",
    "\n",
    "$$ \\mathcal{L}=\\frac {1}{2} \\sum_{p=1}^P\\sum_{r=1}^R A^{(pr)} (x^{(pr)}-\\mu_p-\\nu_r)^2+\\frac {1}{2} \\sum_{r=1}^R \\lambda \\nu_r^2$$\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "For EM algorithm, plz check the below\n",
    "\n",
    "https://github.com/je-suis-tm/machine-learning/blob/master/Wisdom%20of%20Crowds%20project/platt%20burges.ipynb\n",
    "\n",
    "Reference to the original paper\n",
    "\n",
    "https://github.com/je-suis-tm/machine-learning/blob/master/Wisdom%20of%20Crowds%20project/Regularized%20Least%20Squares%20to%20Remove%20Reviewer%20Bias.pdf\n",
    "\n",
    "Reference to Hong Ge's paper\n",
    "\n",
    "http://mlg.eng.cam.ac.uk/hong/unpublished/nips-review-model.pdf\n",
    "\n",
    "Neil Lawrence's personal blog\n",
    "\n",
    "https://inverseprobability.com/2014/08/02/reviewer-calibration-for-nips\n",
    "\n",
    "Neil Lawrence's jupyter notebook\n",
    "\n",
    "https://github.com/lawrennd/conference\n",
    "\n",
    "Others' jupyter notebook\n",
    "\n",
    "https://github.com/leonidk/reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir('K:/ecole/github/televerser/wisdom of crowds')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raise error when zero is encountered in logarithm\n",
    "np.seterr(divide='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute rls loss function\n",
    "def loss_function(x0,data,lambda_,adjacency_matrix):\n",
    "    \n",
    "    #unpack\n",
    "    intrinsic_value=x0[:data.shape[1]]\n",
    "    bias_level=x0[data.shape[1]:]\n",
    "\n",
    "    #convert intrinsic value and bias lvl into matrix\n",
    "    miu_p=np.repeat(np.array(intrinsic_value).reshape(1,-1),\n",
    "                    data.shape[0],axis=0)\n",
    "    nu_r=np.repeat(np.array(bias_level).reshape(-1,1),\n",
    "                   data.shape[1],axis=1)\n",
    "\n",
    "    #compute loss function\n",
    "    rls_loss=np.multiply(np.square(data-miu_p-nu_r),\n",
    "       adjacency_matrix).sum()/2+lambda_*np.square(bias_level).sum()/2\n",
    "    \n",
    "    return rls_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using rls to solve platt burges\n",
    "def regularized_least_square(X,lambda_=0.5,\n",
    "                             adjacency_matrix=[],**kwargs):\n",
    "    \n",
    "    #if not defined\n",
    "    #use complete matrix\n",
    "    if len(adjacency_matrix)==0:\n",
    "        adjacency_matrix=np.ones(X.shape)\n",
    "\n",
    "    #pack\n",
    "    miu_init=X.mean(axis=0).ravel().tolist()[0]\n",
    "    nu_init=X.mean(axis=1).ravel().tolist()[0]\n",
    "    x0=miu_init+nu_init\n",
    "\n",
    "    #rls\n",
    "    result=scipy.optimize.minimize(loss_function,x0,\n",
    "                                   args=(X,lambda_,adjacency_matrix),\n",
    "                                   **kwargs\n",
    "                                  )\n",
    "\n",
    "    if result['success']:\n",
    "\n",
    "        #unpack\n",
    "        intrinsic_value=result['x'][:X.shape[1]]\n",
    "        bias_level=result['x'][X.shape[1]:]\n",
    "\n",
    "        return intrinsic_value,bias_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "y0matrix2019=pd.read_csv('y0matrix2019.csv')\n",
    "\n",
    "y1matrix2020=pd.read_csv('y1matrix2020.csv')\n",
    "\n",
    "monthly=pd.read_csv('monthly.csv')\n",
    "\n",
    "annual=pd.read_csv('annual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index\n",
    "y0matrix2019.set_index('Source Name',inplace=True)\n",
    "\n",
    "y1matrix2020.set_index('Source Name',inplace=True)\n",
    "\n",
    "monthly.set_index('Date',inplace=True)\n",
    "monthly.index=pd.to_datetime(monthly.index)\n",
    "monthly.columns=y0matrix2019.columns\n",
    "\n",
    "annual=annual.pivot(index='Date',\n",
    "                    columns='Name',values='Value')\n",
    "annual.index=pd.to_datetime(annual.index)\n",
    "annual.columns=y0matrix2019.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize forecast by pct return\n",
    "y0_mat_nor=np.mat(\n",
    "    np.divide(y0matrix2019,\n",
    "              monthly['2019-08-31':'2019-08-31'])-1)\n",
    "y1_mat_nor=np.mat(\n",
    "    np.divide(y1matrix2020,\n",
    "              monthly['2019-08-31':'2019-08-31'])-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03496034  0.03416314  0.02020078 -0.00271194  0.00968679  0.02259967\n",
      "  0.00561574  0.03175916]\n",
      "[0.02019064, 0.02024495, 0.00609068, -0.01649482, -0.00426001, 0.00847965, -0.00821187, 0.01734934]\n"
     ]
    }
   ],
   "source": [
    "#current year outlook\n",
    "intrinsic_value,bias_level=regularized_least_square(\n",
    "    y0_mat_nor,lambda_=0,)\n",
    "\n",
    "print(bias_level)\n",
    "\n",
    "#comparison with result from em\n",
    "print([0.02019064,0.02024495,0.00609068,-0.01649482,-0.00426001,\n",
    "0.00847965,-0.00821187,0.01734934])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02044496  0.03448161  0.02317991  0.00170572 -0.00614319 -0.00719274\n",
      " -0.00882933  0.13096969]\n",
      "[0.01352132, 0.02981012, 0.01582776, -0.00265233, -0.01151194, -0.01075301, -0.01477036, 0.12330401]\n"
     ]
    }
   ],
   "source": [
    "#one year ahead outlook\n",
    "intrinsic_value,bias_level=regularized_least_square(\n",
    "    y1_mat_nor,lambda_=0,)\n",
    "\n",
    "print(bias_level)\n",
    "\n",
    "#comparison with result from em\n",
    "print([0.01352132,0.02981012,0.01582776,-0.00265233,-0.01151194,\n",
    "-0.01075301,-0.01477036,0.12330401])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.29570274e-02  9.72272315e-03  2.67925635e-02 -2.04535244e-02\n",
      " -3.98935081e-02 -4.15196790e-02 -8.67932470e-05  8.83924600e-02]\n"
     ]
    }
   ],
   "source": [
    "#demo on incomplete matrix\n",
    "intrinsic_value,bias_level=regularized_least_square(\n",
    "    y1_mat_nor,lambda_=0.5,\n",
    "    adjacency_matrix=np.random.choice([0,1],size=y1_mat_nor.shape))\n",
    "\n",
    "print(bias_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00532965  0.00653886  0.01550822 -0.02454352 -0.03179216 -0.0208043\n",
      " -0.02790948  0.08833376]\n"
     ]
    }
   ],
   "source": [
    "#demo on confidence interval\n",
    "intrinsic_value,bias_level=regularized_least_square(\n",
    "    y1_mat_nor,lambda_=0.5,\n",
    "    adjacency_matrix=np.random.uniform(size=y1_mat_nor.shape))\n",
    "\n",
    "print(bias_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "154px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
